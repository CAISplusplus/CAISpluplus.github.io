---
layout: post
published: true
title: "Lesson 5: Neural Networks, Part 2 (Training)"
headline: "One step forward, one step back"
mathjax: true
featured: true
categories: curriculum 

comments: false
---

## Introduction

In the last lesson, we learned how neural networks can apply a series of transormations on some input data in order to eventually produce a final prediction. This process of transforming the input data by feeding it through layers of artificial neurons, of each of which applies its own weights, biases, and activation functions, is known as "Forward Propagation."

However, you'll note that we never actually went through our training data and used it to train our model parameters (i.e. the the neuron weights and biases). As a result, the transformations that were being applied to the input data were pretty much random, since we randomly initiated the weights and biases. As you could probably predict, this would mean that our final output would be more or less random as well.

In this lesson, you'll see how we can start from this random initialization, use a cost function to measure just how bad our predictions are, and gradually train our network to make more and more meaningful predictions via gradient descent. However, since these neural networks have more than one layer, you'll see that we have to do some extra work in order to calculate these gradient terms for our model parameters.

Once we've gone through the work of training out network, the end result will be a flexible model that is capable of learning even more complex relationships within data than linear regression or logistic regression alone.

**Note:** Once again, we've included both embedded videos and written content for you to go through. This time, the videos will serve as the main portion of the lesson, while the written content (which can be accessed via the links below) will serve as a supplement. We recommend that you check out some of the supplemental material if you have time, but it's not 100% necessary. You may also find it useful to refer back to the supplemental material when working on designing your own machine learning models.

## Neural Network Training: Video Content

To see how exactly we can train neural networks to make predictions that match the training data, we'll continue with our example of trying to predict test scores based on our inputted data consisting of hours studied and hours slept. We'll start off by discussing some ideas that should feel pretty familiar to you if you went through our lesson on linear regression: cost functions and gradient descent.

### Video 1: Cost Function and Gradient Descent

<p style="text-align:center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/5u0jaA3qAGk" frameborder="0" allowfullscreen></iframe>
</p>

**Recap:** Just like we did in linear regression, we'll set up a cost function that will measure just how bad (costly) our predictions are. This will primarily be a function of our model parameters (weights and biases), since we can get different cost values by changing our parameters. When we say that we are "training a network," we really mean that we finding the parameters that minimize our cost function.

To do this, we will use gradient descent to find out how, given our current parameter values, we can tweak our parameters so that we reduce our overall cost. Just as before, we will repeatedly apply these gradient descent steps until we converge on our optimal parameters.

**Notes:**
* That Yann LeCun guy that the speaker in the video mentions is widely considered to be something of a machine learning god by the AI community. You'll see his name pop up a whole lot in our next lesson on Convolutional Neural Networks.


### Video 2: Backpropagation

Next, we'll see how to actually calculate our gradient terms so that we know which way to move our parameters. While this was relatively straightforward in linear regression, it will take some more work when it comes to multi-layer neural networks. While watching the next video, feel free to pause and think whenever necessary. It will likely be helpful to think about what each symbol actually means in English. Here are some good starting points to get your feet planted:
  * $$W^{(i)}$$ is the weight matrix used by the $$i$$th layer in the network. These are the parameters that we eventually want to be able to optimize.
  * $$z^{(i)}$$ is a vector containing the weighted sums of the inputs (and bias terms) of the neurons in the $$i$$th layer. This term directly depends on the weights of this layer, since these weights will dictate the value of the weighted sum.
  * $$a^{(i)}$$ is a vector containing the *activations* of the neurons of the $$i$$th layer, and is equal to the weighted sum of the layer after passing it through the activation function. This term directly depends on the weighted sum $$z^{(i)}$$.
  * And a new one: $$\delta^{(i)}$$ is a vector representing the "error" of each of the individual neurons in the $$i$$th layer. Mathematically, it is given by $$\frac{\partial J}{\partial z^{(i)}}$$, where $$z^{(i)}$$ is the weighted sum of the neurons within layer in question.

We will start by finding the error terms at the right-most end of the network (the neurons closest to the output), and then use the (multivariate) chain rule to propagate this error back through the previous layers until we calculated have the gradient terms for all our model weights. You can think of this process as tracking how changing one neuron's weight somewhere in the network affects that neuron's activation, which in turn affects all the next layer's activations (since they all take in all the previous layer's activations as inputs), which eventually affects the final cost. We want to find out how we can change that one weight so that it shifts the following layers' activations in a way that reduces our final cost.

<p style="text-align:center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/GlcnxUlrtek" frameborder="0" allowfullscreen></iframe>
</p>

**Recap**: In order to actually calculate our gradient terms $$\frac{\partial J}{\partial w_{ij}}$$, we need to be pretty clever in the way that we track how changing one weight anywhere in the network ends up affecting the final cost. To do this, we'll work our way backward through the network: we'll start by calculating the error terms at the neurons closest to the output, and then keep propagating this error through to the earlier layers. (This will require us to apply the chain rule a pretty absurd number of times.) Along the way, we'll see which weights are responsible for most of the error in the network, and then adjust their gradient terms accordingly.

As we propagate the error backward, we'll eventually begin to reveal which way we should change the weights early on in our network so that they change the subsequent activations in a positive way (that is, in a way that reduces our final cost). Once we have all our gradient terms calculated, we'll finally know which way to apply our gradient descent step so that we end up decreasing our cost function, and making our predictions just a little more accurate.

**Notes**:
* In case this has you lost, don't worry. Almost everyone feels lost when they learn about backpropagation the first couple times around. If you'd like to try looking at another source, check out [**this section**](http://neuralnetworksanddeeplearning.com/chap2.html) on backpropagation from Mike Nielson's online book, Neural Networks and Deep Learning. You may find his explanations more intuitive than most.
* We've also written our own more mathematical description of backpropagation [**here**](../curriculum-supplement/lesson5supplement#backpropagation) in case you want to go even more in-depth.
* This isn't mentioned in the video, but when we go through the process of backpropagation for deep neural networks (that is, neural networks with many hidden layers), we often run into something called the "vanishing gradient problem." Essentially, what happens is that after applying the chain rule so many times, our gradient terms end up requiring a whole lot of chained multiplications in order to be evaluated. Since we tend to work with smaller numbers in neural networks, this means that we end up multiplying over a whole lot of small values, which results in a tiny final gradient. This can be bad news for deep networks, since it can slow down the gradient descent process to a crawl. Here's a more detailed explanation that we've put together on this topic: [**The Unstable Gradient Problem**](../curriculum-supplement/lesson5supplement#unstable-gradient).

### Video 3: Training

<p style="text-align:center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/9KM9Td6RVgQ" frameborder="0" allowfullscreen></iframe>
</p>

**Recap:** Although gradient descent is a super powerful tool, it isn't without its flaws. Turns out, it may not always converge on the optimal parameters for our model: it may end up overshooting the optimal point, finding a local minimum of our cost function instead of the global minimum, etc. Thankfully, there's a whole slew of optimization techniques that we can use to minimize our cost function by tweaking our network parameters, each with its unique differences from pure gradient descent. One such example of another optimization technique is called BFGS.

As we use BFGS to train our network while plotting out our cost values over time, we will see that our cost decreases significantly; this means that the intelligent optimization is doing a good job of fitting our model parameters to the training data. Before being able to make actual real-world predictions, however, we'll have to perform some extra steps to make sure that our model hasn't been *overfit* to the training data.

**Notes:**
* For a more in-depth look on the nuances behind different optimization techniques and ways in which we can further improve upon regular gradient descent, see our more detailed write-up here: [**Optimization in Practice**](../curriculum-supplement/lesson5supplement#optimization-in-practice). Topics include gradient descent with momentum, adaptive learning rates, and second-order algorithms, to name a few.

### Video 4: Overfitting, Testing, and Regularization

<p style="text-align:center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/S4ZUwgesjS8" frameborder="0" allowfullscreen></iframe>
</p>

**Recap:** Data is never perfect: our observations contain both signal (which reflects some real, underlying process), and random noise. If we make the model fit our observations too closely, we will end up fitting it to this noise as well, which will make for some pretty weird and unintuitive predictions.

In order to diagnose overfitting, we'll hide a part of our observed data from the model (we'll call this the *test set*), and only train our model based on the remaining data (we'll call this the *training set*). Measuring our model's performance on the test set will allow us to get an unbiased view of how well our model can make generalized predictions from unseen data, so if our test set cost is much higher than our training set cost, we can be fairly certain that our model has overfit the training data at the expense of generalized prediction ability.

Potential fixes for overfitting include getting more data (if possible), and using a technique called *regularization*. Regularization penalizes overly complex models by adding the squared-magnitudes of the model weights to the cost function, often resulting in smoother, more *robust* models that are more capable of making general predictions in the real world.

**Notes:**
* If you're curious, we've put together a more detailed [**write-up**](../curriculum-supplement/lesson5supplement#regularization) on ways in which we can prevent overfitting from happening in neural networks. Methods discussed include L2 Regularization, early stopping, ensemble methods, and dropout. These will probably be good to know if you plan on implementing your own neural networks in the future.

<br>


## Conclusion

If you made it through these past two lessons, you should hopefully have a good idea now of how the architecture of a neural network is set up, and how neural networks use their layers of neurons to gradually transform input data into a final prediction. (Remember: multiply inputs by weights, add it all up -- including a bias, apply an activation function, and repeat.)

You should hopefully also have a general notion of how we go about training these neural networks, and also an idea of what challenges can arise during the training process. (For example, vanishing gradients, local minima, overfitting, etc.)

If some of the topics brought up in these last two lessons still don't quite make sense to you, that's perfectly ok. This material is pretty difficult for most people to pick up at first, but only gets better with patience and practice. If you have any questions, feel free to shoot us an email at <a href='mailto:caisplusplus@gmail.com'>caisplusplus@gmail.com</a> and we will do our best to get back to you as soon as we can.

Otherwise, stay tuned for the next lesson, in which we'll use the theoretical basis developed in these lessons to proceed onto a more powerful type of model: the Convolutional Neural Network. Convolutional Neural Networks are a specific type of neural network designed for processing and understanding images, and are still at the forefront of machine learning research. 

Now that you've built up a basic machine learning foundation, it's time to let the real fun begin!

<br>

<h2>Sources</h2>
<ul>
  <li><a href='http://neuralnetworksanddeeplearning.com'>neuralnetworksanddeeplearning.com</a></li>
  <li>
    <a href='http://hagan.okstate.edu/NNDesign.pdf'>
      Neural Network Design by Hagan
    </a>
  </li>
  <li>
    <a href='https://www.amazon.com/Deep-Learning-Adaptive-Computation-Machine/dp/0262035618'>
      Deep Learning (Adaptive Computation and Machine Learning Series) by
      Goodfellow, Bengio, Courville
    </a> 
  </li>
  <li>
    <a href='http://cs231n.github.io/'>CS231n Convolutional Neural Networks for
    Visual Recognition Class Notes</a>
  </li>
  <li>
    <a
    href='https://jamesmccaffrey.wordpress.com/2013/11/05/why-you-should-use-cross-entropy-error-instead-of-classification-error-or-mean-squared-error-for-neural-network-classifier-training/'>
      Why You Should Use Cross-Entropy Error Instead Of Classification Error Or
      Mean Squared Error For Neural Network Classifier Training by James D.
      McCaffery
    </a>
  </li>
</ul>

